{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acoustic-spouse"
   },
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sitting-soviet"
   },
   "source": [
    "## Problem 1\n",
    "In this problem we will consider the Linear Regression model. In other words, our model is a linear function of the form \n",
    "\n",
    "$$f(x_1, \\dots, x_p) = \\beta_0 + \\beta_1 x_1 +  \\dots + \\beta_p x_p.$$\n",
    "\n",
    "In Exercise 1, we saw that the regression function minimizes the **expected** square error, for any $x = (x_1, \\dots, x_p)$\n",
    "\n",
    "$$\\operatorname{E}\\left[\\left(Y - f(x_1, \\dots, x_p)\\right)^2 \\mid X = x\\right] = \n",
    "\\operatorname{E}\\left[\\left(Y - (\\beta_0 + \\beta_1 x_1 +  \\dots + \\beta_p x_p)\\right)^2 \\mid X = x\\right].\n",
    "$$\n",
    "\n",
    "In finite samples, we cannot compute the theoretical expectation, therefore, we minimize the **mean** square error \n",
    "\n",
    "$$MSE(\\beta_1, \\dots, \\beta_p) = \\frac{1}{n}\\sum_{i = 1}^{n}\\left(Y_i - (\\beta_0 + \\beta_1 x_{i1} +  \\dots + \\beta_p x_{ip})\\right)^2.$$\n",
    "\n",
    "Notice that $MSE = RSS/n$, where $RSS$ is the residual sum of squares defined in the lecture notes.\n",
    "\n",
    "Training a linear regression model means finding the set of parameters $\\beta_1, \\dots, \\beta_p$ that minimize the $MSE$. In machine learning, the function that we want to minimize is usually called **cost** function.\n",
    "\n",
    "We will consider two approaches to train a Linear Regression model.\n",
    "\n",
    "1. **Analytical solution** --- This method gives a closed-form solution to compute the optimal weights ($\\beta$'s) for the regression line.\n",
    "2. **Gradient descent** --- This method is an iterative optimization techniques that starts with some initial guess of the weights vector $\\beta$ and it updates it in order to minimize the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "opponent-moore"
   },
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    " #coucou\n",
    " #coucou en dessous de mon coucou\n",
    " #1 2 3 coucou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1646855768671,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "funky-asian"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "driving-rates"
   },
   "source": [
    "### 1. Generate synthetic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waiting-mexican"
   },
   "source": [
    " Let us start by generating some synthetic data set. In this problem we assume that our regression model has only one predictor and writes\n",
    " \n",
    " $$f(X_1) = \\beta_0 + \\beta_1 X_1,$$\n",
    " \n",
    "where $\\beta_0 = 4$ and $\\beta_1 = 3$. \n",
    "\n",
    "Also, we assume that:\n",
    "- the predictor $X_1$ follows a uniform distribution between 0 and 2, i.e., $X_1 \\sim U[0, 2]$,\n",
    "- the response $Y = f(X_1)+ N(0, 1) = 4 + 3 X_1 + N(0, 1)$, where $N(0, 1)$ denotes a standard normal random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "applicable-location"
   },
   "source": [
    "* Import `numpy` as `np`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1646855768671,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "adult-ghana"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "victorian-minute"
   },
   "source": [
    "* Generate 100 observations of the predictor `X1`.\n",
    "\n",
    "_Hint_: use the function `rand` from `np.random`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1646855770715,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "backed-collar",
    "outputId": "a854682f-a589-49e8-e046-437cb311c951"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30417636, 1.54524785, 1.47066165, 0.08239842, 0.04684385,\n",
       "       0.74472126, 0.75629949, 1.321088  , 1.80149829, 0.57946615,\n",
       "       0.00415426, 1.28017435, 1.78319159, 0.4325572 , 0.76487928,\n",
       "       0.1773753 , 0.23527805, 1.76773661, 0.0711355 , 0.31199725,\n",
       "       0.63380397, 1.45381714, 1.24277585, 0.16064499, 1.16884182,\n",
       "       0.76569887, 0.38180968, 0.44781123, 0.49578703, 0.12329508,\n",
       "       0.47955041, 1.53708732, 0.9247516 , 0.34560001, 1.38957868,\n",
       "       0.70690278, 1.29797741, 1.93501776, 1.43674174, 0.79586756,\n",
       "       1.45389473, 0.91060621, 0.10314836, 0.98678912, 1.30563253,\n",
       "       0.18899903, 0.16195826, 1.27680795, 0.43175328, 0.56387363,\n",
       "       1.65160277, 1.56521865, 0.50547975, 1.52119098, 1.55839714,\n",
       "       1.42307614, 1.51923634, 0.92542153, 1.76649531, 1.5831544 ,\n",
       "       0.22245914, 0.16626819, 0.6904543 , 0.38391335, 0.08029163,\n",
       "       0.36359016, 0.33587524, 0.57028105, 1.84511756, 1.16435392,\n",
       "       1.77979173, 0.66749512, 1.39510104, 0.99725596, 1.22606434,\n",
       "       1.17373612, 1.01694533, 1.44727382, 0.12197242, 1.30808733,\n",
       "       1.37422601, 1.5643979 , 0.14565654, 1.9423507 , 0.83779187,\n",
       "       0.46561245, 1.2802029 , 0.43118394, 0.434089  , 0.9065804 ,\n",
       "       1.64476379, 0.63749326, 1.11982089, 0.6609682 , 1.93161572,\n",
       "       1.95253226, 1.37957715, 0.60922805, 1.71403402, 0.25585561])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomState(42)\n",
    "x1=2*(np.random.rand(100))\n",
    "x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fitting-waterproof"
   },
   "source": [
    "* Generate 100 observations of the response `Y`.\n",
    "\n",
    "_Hint_: use the function `randn` from `np.random`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 760,
     "status": "ok",
     "timestamp": 1646855773201,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "controversial-presentation"
   },
   "outputs": [],
   "source": [
    "y=np.array((4+(3*x1)+(np.random.randn(100))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "signal-cheese"
   },
   "source": [
    "* Plot the scatter of `X1` and `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 806,
     "status": "ok",
     "timestamp": 1646855777982,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "automated-nomination",
    "outputId": "6226ab46-6729-4cdc-ceee-9846c050049b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2d6cf6e8c40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x1,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "individual-deployment"
   },
   "source": [
    "### 2. Train linear regression with analytical solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "educated-message"
   },
   "source": [
    "At this point we train the linear regression with the analytical solution. \n",
    "\n",
    "Denote by $X$ the matrix containing the predictor values. In our case, the first column of $X$ contains all 1's (for the intercept) and the second column contains the predictor $X_1$.\n",
    "\n",
    "The optimal vector $\\beta^* = (\\beta_0^*, \\beta_1^*)$ that minimizes the cost function $MSE(\\beta_0, \\beta_1)$, is given by\n",
    "\n",
    "$$\\beta^* = (X^T X)^{-1} X^T Y.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dimensional-latter"
   },
   "source": [
    "* Create the matrix `X`.\n",
    "\n",
    "_Hint_: Use the function `ones` from `np` to generate a column of 1's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1054,
     "status": "ok",
     "timestamp": 1646855782405,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "_x57aZn07_td"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1646855784537,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "unique-worship",
    "outputId": "5bdd35f6-565e-430e-ce50-760a2835ccf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.transpose(np.array([np.ones(100),x1]))\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sacred-sapphire"
   },
   "source": [
    "* Use the formula above to compute the optimal parameter vector $\\beta^*$.\n",
    "\n",
    "_Hint_: Use the functions `dot`, `transpose` from `np`, and the function `inv` from `np.linalg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1646855791852,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "changing-vector"
   },
   "outputs": [],
   "source": [
    "X_transpose = np.transpose(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "06dc922b"
   },
   "outputs": [],
   "source": [
    "#inv_Xtrans_X= np.linalg.inv(np.dot(X_transpose,X))\n",
    "#np.dot(np.dot(inv_Xtrans_X,X_transpose),y)\n",
    "#t(X_transpose,X))\n",
    "#np.dot(np.dot(inv_Xtrans_X,X_transpose),y)\n",
    "#beta_star=np.dot(np.dot(np.linalg.inv(np.dot(X_transpose,X)),X_transpose),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1646855800253,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "7c11bc09"
   },
   "outputs": [],
   "source": [
    "beta_star=np.linalg.inv(X_transpose @ X) @ X_transpose @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1646855817558,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "3b4ed1f2",
    "outputId": "65d028e3-962b-434b-cdac-90ff83134000"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.93494054, 3.14343134])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sustained-corrections"
   },
   "source": [
    "* Using the optimal weights obtained above, compute the model predictions on the training data `X`.\n",
    "\n",
    "_Hint_: Recall that the predictions can be computed with the formula $ \\widehat Y = X \\beta^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1646855951120,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "cognitive-picture"
   },
   "outputs": [],
   "source": [
    "y_predicted = beta_star[0] + beta_star[1]*x1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1646855953100,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "ef9f9e02",
    "outputId": "4946a4a6-22c0-4770-ab7b-af0b351ca368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.89109805  8.79232108  8.55786446  4.19395432  4.08219095  6.27592068\n",
      "  6.31231606  8.08768998  9.59782672  5.7564526   3.94799918  7.95908073\n",
      "  9.54028089  5.2946544   6.33928604  4.49250763  4.67452094  9.4916992\n",
      "  4.15855011  4.91568246  5.92725982  8.5049149   7.84152109  4.43991702\n",
      "  7.60911456  6.34186236  5.13513304  5.34260438  5.49341301  4.32251016\n",
      "  5.44237432  8.76666901  6.84183369  5.02131045  8.30298571  6.1570409\n",
      "  8.01504341 10.01753603  8.45123954  6.43669559  8.50515881  6.79736863\n",
      "  4.25918031  7.03684439  8.03910674  4.52904601  4.44404522  7.94849868\n",
      "  5.29212733  5.70743857  9.12664045  8.85509789  5.52388144  8.71669995\n",
      "  8.83365495  8.40828267  8.71055566  6.84393958  9.48779726  8.91147771\n",
      "  4.63422558  4.45759319  6.10533624  5.14174581  4.18733176  5.07786125\n",
      "  4.99074128  5.72757987  9.73494092  7.59500714  9.52959365  6.03316563\n",
      "  8.32034487  7.0697462   7.78898961  7.62449945  7.13163837  8.48434641\n",
      "  4.31835248  8.04682325  8.25472564  8.85251794  4.39280189 10.0405866\n",
      "  6.56848175  5.3985613   7.95917046  5.29033767  5.29946951  6.78471379\n",
      "  9.10514259  5.93885682  7.45502063  6.0126487  10.00684195 10.07259164\n",
      "  8.27154659  5.8500071   9.32288879  4.73920508]\n"
     ]
    }
   ],
   "source": [
    "#y_predicted = X @ beta_star\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sweet-regulation"
   },
   "source": [
    "### 3. Plot predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fifteen-roommate"
   },
   "source": [
    "* Plot the predictions obtained above, together with the scatter of `X1` and `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1646855991603,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "herbal-romance",
    "outputId": "419903df-a88e-4624-e771-54ef31aecb57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2d6d0413df0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_min = x1.min()\n",
    "x_max = x1.max()\n",
    "\n",
    "# plotting a line plot after changing it's width and height\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(7)\n",
    "\n",
    "plt.scatter(x1,y,color='b',label='data')\n",
    "plt.scatter(x1,y_predicted,color='r',label='prediction')\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chemical-denial"
   },
   "source": [
    "### 4. Compare solutions with scikitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unknown-forge"
   },
   "source": [
    "* Fit a linear regression model using the `scikit-learn` library.\n",
    "\n",
    "_Hint_: Be careful, the `fit` method from `scikit-learn` requires the predictor matrix without the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1646856272980,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "dying-demographic",
    "outputId": "3569205c-c5ea-427c-b2ef-e1dadb1e4643"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(x1.reshape((-1, 1)),y.reshape((-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "international-transmission"
   },
   "source": [
    "* From the fitted object, extract the estimated intercept and slope and compare it to the ones you computed with the formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1646856307281,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "technical-offer",
    "outputId": "9e3277c0-3efe-4498-c19a-56c0355eab57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept (beta,sklearn):  (3.9349405389886307, 3.9349405389886343)\n",
      "coeff (beta,sklearn):  (3.143431343450475, 3.143431343450472)\n"
     ]
    }
   ],
   "source": [
    "print('intercept (beta,sklearn): ',(beta_star[0],model.intercept_[0]))\n",
    "print('coeff (beta,sklearn): ',(beta_star[1],model.coef_[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d73a7c8d"
   },
   "source": [
    "*They are the same!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "charged-recall"
   },
   "source": [
    "### 5. Train linear regression with batch gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "defined-manitoba"
   },
   "source": [
    "The general idea of gradient descent is to update the parameters iteratively to minimize the cost function.\n",
    "\n",
    "**Note**: when using gradient descent, it is always better have all features on the same scale. This can be done in the data transformation step using the `StandardScaler` class from `sklearn.preprocessing`. \n",
    "This ensures that the algorithm converges to the optimal solution much faster.\n",
    "In this example, however, we don't need to worry about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "regulated-brisbane"
   },
   "source": [
    "Recall that in our case the cost function is\n",
    "\n",
    "$$MSE(\\beta_0, \\beta_1) = \\frac{1}{n}\\sum_{i = 1}^{n}(Y_i -\\beta_0 - \\beta_1 X_{i1})^2.$$\n",
    "\n",
    "The idea of gradient descent is to start with some initial guess of the vector $\\beta = (\\beta_0, \\beta_1)$, and iteratively update it in the direction that points \"most **downhill**\" (remember that we want to **minimize** the cost function).\n",
    "\n",
    "The **gradient vector** of the MSE is denoted as\n",
    "\n",
    "$$ \\nabla MSE(\\beta) = \\begin{bmatrix}\n",
    "           \\dfrac{\\partial MSE(\\beta)}{\\partial \\beta_0} \\\\\n",
    "           \\dfrac{\\partial MSE(\\beta)}{\\partial \\beta_1}\n",
    "         \\end{bmatrix},$$\n",
    "\n",
    "where each element is the partial derivative of the $MSE$ with respect to $\\beta_1$ and $\\beta_2$.\n",
    "\n",
    "Notice that the **gradient vector of any cost function** gives us the direction that points \"most **uphill**\". \n",
    "Since the **gradient** vector points toward the most **uphill** direction, then the **negative gradient** points toward the most **downhill** direction.\n",
    "\n",
    "In linear regression with the $MSE$ cost function, the **negative gradient** vector writes\n",
    "\n",
    "$$ -\\nabla MSE(\\beta) = -\\frac{2}{n} X^T (X\\beta - Y).$$\n",
    "\n",
    "Based on the negative gradient vector, at each iteration, we update the previous parameter value $\\beta_{\\text{old}}$, as follows\n",
    "\n",
    "$$ \\beta_{\\text{new}} = \\beta_{\\text{old}} - \\alpha\\ \\nabla MSE(\\beta_{\\text{old}}),$$\n",
    "\n",
    "where $\\alpha$ is the learning rate, a **crucial** tuning parameter for the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "homeless-nation"
   },
   "source": [
    "* We now implement the batch gradient descent algorithm. Fill in the `??`. Which value of `beta` do you obtain? What happens if you change `alpha`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1646857953232,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "zazcL2G8YObB",
    "outputId": "de092690-4839-4046-d272-f9e67e5dce2c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112072,
     "status": "ok",
     "timestamp": 1646859202876,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "efficient-member",
    "outputId": "7f74d623-1dd3-420e-fcb9-0ef80a561519"
   },
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "n_iterations = 10000000\n",
    "\n",
    "beta = np.random.rand(2, 1) # randomly initialize the parameter vector\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    gradient = -((2/n_iterations)*np.transpose(x1))@((beta[0]+beta[1]*x1)-y)  # update gradient\n",
    "    beta = beta + alpha * gradient # update beta\n",
    "\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "provincial-magazine"
   },
   "source": [
    "* Fill in the `??` to code the function that plots the first 10 updates of the batch gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "executionInfo": {
     "elapsed": 224,
     "status": "error",
     "timestamp": 1646860524588,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "considerable-legislature",
    "outputId": "d564d16e-fb87-48b1-99bb-3abb311fadbb"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-75-5c831f73900f>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    beta = beta + alpha @ gradient # update beta\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def plot_batch_gradient_descent(X, Y, alpha = 0.1, n_iterations = 100, seed = 42):\n",
    "    '''\n",
    "    numpy.ndarray numpy.ndarray float float float -> list\n",
    "    produces a list with the updates of the parameter vector\n",
    "    as a side effect, it plots the first 10 updates of the regression function\n",
    "    '''\n",
    "    \n",
    "    nRows, nCols = X.shape\n",
    "    \n",
    "    beta_path = []\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    beta = np.random.rand(nCols, 1) # randomly initialize the parameter vector\n",
    "    \n",
    "    beta_path.append(beta)\n",
    "    \n",
    "    plt.plot(X[:,1], Y, \"b.\")\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        gradient = -((2/n_iterations)*np.transpose(x1))@((beta[0]+beta[1]*x1-y) # update gradient\n",
    "        beta = beta + alpha * gradient # update beta\n",
    "        beta_path.append(beta)\n",
    "    \n",
    "        if (i < 10):\n",
    "            plt.plot(X[:, 1], X @ beta, \"r-\")\n",
    "            \n",
    "    return(np.array(beta_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "durable-overhead"
   },
   "source": [
    "* Call the function `plot_batch_gradient_descent` with different values of `alpha`. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8HaOvRUGdnId"
   },
   "outputs": [],
   "source": [
    "#my guess: lower the alpha, more precise the observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klwfTgzXdmW2"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "substantial-interval"
   },
   "outputs": [],
   "source": [
    "plot_batch_gradient_descent(alpha=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "existing-reduction"
   },
   "source": [
    "### 6. Train linear regression with stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brilliant-spring"
   },
   "source": [
    "The gradient descent scheme that we coded above is known as **batch** gradient descent. This is because at every step it uses **all** the training data to update the gradient vector and the parameter vector $\\beta$.\n",
    "This makes it very slow when the training dataset contains many observations.\n",
    "\n",
    "At the other end of the spectrum, we have the **stochastic** gradient descent. Here, at every step, we randomly choose one random observation (row) from the dataset, to update the gradient vector and the parameter vector $\\beta$. In other words, the updates at every step depend only on a single observation.\n",
    "\n",
    "This makes the algorithm much faster to compute each iteration, compared to the batch version. On the other hand, since our updates depend on a single observation, this algorithm is more \"erratic\" than the batch version, and it will never settles at the minimum point, unless we \"stop it\".\n",
    "\n",
    "This is why, in the stochastic gradient descent, it is important to have a learning rate $\\alpha$ that slowly decays to zero, as the number of iterations increases. \n",
    "One common choice is to define the learning rate as follows\n",
    "\n",
    "$$\\alpha(t) = \\dfrac{\\eta_0}{t^{k}},$$\n",
    "\n",
    "where $t$ denotes the number of iterations, and $\\eta_0$ and $k$ are hyperparameters. The defaults values in `scikit-learn` are $\\eta_0 = 0.01$ and $k = 0.25$ ([see link](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "completed-translation"
   },
   "source": [
    "* Import the `SGDRegressor` class from `sklearn.linear_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 216,
     "status": "ok",
     "timestamp": 1646859514978,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "careful-indie"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hungarian-wound"
   },
   "source": [
    "* Create an object of class `SGDRegressor` and fill in the `??`. Also, look at the documentation of the function and explain the different arguments.\n",
    "\n",
    "**max_iter is the maximum iteration we want the algorithm to do. tol is the stopping criterion. eta0 = is the initial learning rate. Penalty is which regularizer we want to use.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1646859964612,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "dominican-mills"
   },
   "outputs": [],
   "source": [
    "sgd_reg = SGDRegressor(max_iter=10000, tol=1e-3, eta0=0.01, penalty=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "welcome-exhaust"
   },
   "source": [
    "* Fit the stochastic gradient descent on the data. Fill in the `??`.\n",
    "\n",
    "_Hint_: Be careful, the `fit` method from `scikit-learn` requires the predictor matrix without the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1646860009590,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "distinct-ethics",
    "outputId": "a6666ba5-3b2a-4ce2-8a9f-4c58e6970ef6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(max_iter=10000, penalty=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg.fit(x1.reshape(-1,1), y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "civil-publication"
   },
   "source": [
    "* From the fitted object, extract the estimated intercept and slope and compare it to the ones you computed with the analytical solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1646860150658,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "coated-challenge",
    "outputId": "7bc39e47-fa16-4659-ffcd-4cd66b06ec1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept (beta,sdgreg):  (4.1529003550249985, 3.8104773174268813)\n",
      "coeff (beta,sdgreg):  (2.9488077039270353, 3.231446491689398)\n"
     ]
    }
   ],
   "source": [
    "print('intercept (beta,sdgreg): ',(beta_star[0],sgd_reg.intercept_[0]))\n",
    "print('coeff (beta,sdgreg): ',(beta_star[1],sgd_reg.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "italic-complexity"
   },
   "source": [
    "### 7. Plot the downhill path of batch and stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coastal-blowing"
   },
   "source": [
    "We now show the downhill path of the batch and stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1646860172514,
     "user": {
      "displayName": "Murielle Furibond",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08986639471398520603"
     },
     "user_tz": -60
    },
    "id": "adult-miami"
   },
   "outputs": [],
   "source": [
    "def plot_stochastic_gradient_descent(X, Y, eta0 = 0.1, n_iterations = 100, seed = 42):\n",
    "    '''\n",
    "    numpy.ndarray numpy.ndarray float float float -> list\n",
    "    produces a list with the updates of the parameter vector\n",
    "    as a side effect, it plots the first 10 updates of the regression function\n",
    "    '''\n",
    "    \n",
    "    nRows, nCols = X.shape\n",
    "    \n",
    "    beta_path = []\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    beta = np.random.rand(nCols, 1) # intialize parameter\n",
    "    \n",
    "    beta_path.append(beta)\n",
    "    \n",
    "    plt.plot(X[:,1], Y, \"b.\")\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        for j in range(nRows):\n",
    "            \n",
    "            random_row = np.random.randint(nRows)\n",
    "            Xj = X[random_row:random_row+1]\n",
    "            Yj = Y[random_row:random_row+1]\n",
    "            \n",
    "            gradient = 2 * Xj.T @ (Xj @ beta - Yj) # update gradient\n",
    "            alpha = eta0 / (j + i * nRows + 1)**0.25 # update learning rate\n",
    "            beta = beta - alpha * gradient # update beta\n",
    "            beta_path.append(beta)\n",
    "\n",
    "            if (i == 0 and j < 10):\n",
    "                plt.plot(X[:, 1], X @ beta, \"r-\")\n",
    "            \n",
    "    return(np.array(beta_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "classified-history"
   },
   "source": [
    "* Call the functions `plot_batch_gradient_descent` and `plot_stochastic_gradient_descent` with the default arguments. Save the results into the objects `path_batch` and `path_stoch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exterior-healing"
   },
   "outputs": [],
   "source": [
    "path_batch = plot_batch_gradient_descent()\n",
    "path_stoch = plot_stochastic_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "outside-lobby"
   },
   "source": [
    "* Fill in the `??` to plot the downhill paths of the **batch** and the **stochastic** gradient descent algorithms. Which differences do you notice between the two methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sophisticated-silicon"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(??, ??, \"r-s\", linewidth=1, label=\"Stochastic\")\n",
    "plt.plot(??, ??, \"b-o\", linewidth=1, label=\"Batch\")\n",
    "plt.legend(loc=\"upper left\", fontsize=16)\n",
    "plt.xlabel(\"$\\\\beta_0$\", fontsize = 20)\n",
    "plt.ylabel(\"$\\\\beta_1$\", fontsize = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "still-officer"
   },
   "source": [
    "## Problem 2\n",
    "Suppose our data is generated by the additive error model\n",
    "$$ Y = f(X) + \\epsilon,$$\n",
    "\n",
    "where $f:\\mathbb{R}^p \\to \\mathbb{R}$ is a (deterministic) function, and $\\epsilon$ is a noise\n",
    "variable with $\\mathrm{E}(\\epsilon)= 0$\n",
    "and $\\mathrm{V}(\\epsilon) = \\sigma^2_\\epsilon$.\n",
    "\n",
    "Define the joint distribution of the random samples\n",
    "$D = (X_1, \\dots, X_n, Y_1, \\dots, Y_n) \\sim P_D$.\n",
    "\n",
    "Let $\\hat f$ be an estimate of the regression function $f$. \n",
    "Recall that $\\hat f$ is a random variable\n",
    "since it depends on the training data  $D$ that are random. \n",
    "Therefore, the expected value of $\\hat f$ can be written as\n",
    "\\begin{align*}\n",
    "\\mathrm{E}_{P_D}[\\hat f] = \\int \\hat f \\ dP_D.\n",
    "\\end{align*}\n",
    "\n",
    "Consider a new (**fixed**) data point $X = x_0$, which is independent of the training data.\n",
    "\n",
    "Conditional on this value, we have that\n",
    "$Y = f(x_0) + \\epsilon \\sim P_{Y\\mid x_0}$, where $P_{Y|x_0}$ denotes the\n",
    "conditional distribution of $Y$ given $X = x_0$.\n",
    "Therefore, the conditional expectation of $Y$, given $X = x_0$, can be written\n",
    "as\n",
    "\\begin{align*}\n",
    "\\mathrm{E}_{P_{Y\\mid x_0}}[Y \\mid X = x_0] = \\int y \\ dP_{Y\\mid x_0}.\n",
    "\\end{align*}\n",
    "\n",
    "Show the following Bias-Variance decomposition of the expected prediction error at the new \n",
    "point $X = x_0$:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathrm{E}rr_{\\hat f} (x_0) &= \\mathrm{E}_{P_D}\\mathrm{E}_{P_{Y\\mid x_0}}[ (Y-\\hat f(x_0))^2 \\mid X_0 = x_0 ]\\\\\n",
    "& = \\sigma_\\epsilon^2 + [\\mathrm{E}_{P_D} \\hat f(x_0) - f(x_0)]^2\n",
    "+ \\mathrm{E}_{P_D}[\\hat f(x_0) - \\mathrm{E}_{P_D} \\hat f(x_0) ]^2\\\\\n",
    "& = \\text{Irreducible Error} + \\text{Bias}^2 + \\text{Variance}.\n",
    "\\end{align}\n",
    "\n",
    "_Hint_: Note that \n",
    "$$ \\mathrm{E}_{P_D}\\left[ (f(x_0) - \\mathrm{E}_{P_D}\\hat f(x_0))(\\mathrm{E}_{P_D} \\hat f(x_0) - \\hat f(x_0))\\right] = 0,$$\n",
    "since $\\mathrm{E}_{P_D}\\left[\\mathrm{E}_{P_D} \\hat f(x_0) - \\hat f(x_0)\\right] = 0$.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise_02.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
