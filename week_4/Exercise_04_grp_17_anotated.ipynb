{"cells":[{"cell_type":"markdown","metadata":{"id":"VCM9mnDSFHkA"},"source":["# Machine Learning: Exercise session 04"]},{"cell_type":"markdown","metadata":{"id":"bVNU4rwyFHkG"},"source":["In this exercise session we will focus on Ridge and Lasso regression. You will learn how to fit, predict, and cross-validate these models.\n","\n","In the first problem, we will continue using the housing dataset where we added several interaction terms, and one additional variable named `X1`. You can download the data from Moodle in this week's section.\n","\n","The second problem is theoretical and not due for hand-in. There, we will derive the closed-form solution for the Ridge regression (notice that Lasso regression has no closed-form solution)."]},{"cell_type":"markdown","metadata":{"id":"Fu_x4htqFHkM"},"source":["## Problem 1"]},{"cell_type":"markdown","metadata":{"id":"tSspuYM0FHkU"},"source":["### 0. Load data and create a test set"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"GvwtcP0AFHkc","executionInfo":{"status":"ok","timestamp":1648128878597,"user_tz":-60,"elapsed":280,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"3RUNpKXsFHkf"},"source":["* Import the clean housing dataset with `pd.read_csv` and take a quick look at it, to verify that it is in the desired shape (display the dataframe, check its \"infos\")."]},{"cell_type":"code","execution_count":3,"metadata":{"ExecuteTime":{"end_time":"2021-03-11T17:40:07.020276Z","start_time":"2021-03-11T17:40:05.837658Z"},"colab":{"base_uri":"https://localhost:8080/","height":349},"id":"ScWb-F85FHki","executionInfo":{"status":"error","timestamp":1648129001315,"user_tz":-60,"elapsed":290,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}},"outputId":"866d0833-4e4f-4d2e-8590-25c94deceed5"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-3f7586d2d7d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"housing_interactions.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'housing_interactions.csv'"]}],"source":["df=pd.read_csv(\"housing_interactions.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5tpr-XydFHkj","executionInfo":{"status":"aborted","timestamp":1648128879189,"user_tz":-60,"elapsed":307,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["df\n","df.info()"]},{"cell_type":"markdown","metadata":{"id":"17AmRJmzFHkn"},"source":["* Separate the dataframe into the features `X` and the target variable `y`: (remember, we want to predict the median house value, given the other variables)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sni8CdqNFHkr","executionInfo":{"status":"aborted","timestamp":1648128879191,"user_tz":-60,"elapsed":308,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["X = df[[\"longitude\",\"latitude\", \"housing_median_age\",\"median_income\",\"rooms_per_bedroom\",\"rooms_per_household\",\"people_per_household\",\"ocean_proximity_enc\"]]\n","Y = df[[\"median_house_value\"]]"]},{"cell_type":"markdown","metadata":{"id":"iM9bcSjVFHks"},"source":["* Using the function `train_test_split`, split the dataset into training and test set. Set `test_size = 0.95` and `random_state = 12`. \n","\n","*Notice that we choose a very large fraction of test data because we want to see whether the Ridge and Lasso regression can handle the high-dimensional setting.*"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-03-11T17:40:07.132428Z","start_time":"2021-03-11T17:40:07.023280Z"},"id":"-c9KaUChFHkv","executionInfo":{"status":"aborted","timestamp":1648128879192,"user_tz":-60,"elapsed":308,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","x_train,x_test, y_train, y_test = train_test_split(X,Y, test_size=.95, random_state=12)"]},{"cell_type":"markdown","metadata":{"id":"FRoXMXKiFHkx"},"source":["### 1. Define models"]},{"cell_type":"markdown","metadata":{"id":"hV_bI_WOFHky"},"source":["* Using the class `Ridge` from `sklearn.linear_model`, instantiate a ridge regression object with penalty parameter equal to 0.1. Furthermore, set `fit_intercept=True`, and `normalize=True`. Call this object `ridge_reg`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9kN3YGzcFHkz","executionInfo":{"status":"aborted","timestamp":1648128879193,"user_tz":-60,"elapsed":308,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["from sklearn.linear_model import Ridge\n","ridge_reg = Ridge(alpha=0.1, fit_intercept=True, normalize= True)\n"]},{"cell_type":"markdown","metadata":{"id":"qQJM67IkFHk0"},"source":["* Using the class `Lasso` from `sklearn.linear_model`, instantiate a ridge regression object with penalty parameter equal to 0.1. Furthermore, set `fit_intercept=True`, `normalize=True`, and `max_iter=1e5`. Call this object `lasso_reg`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NoFRYw0_FHk1","executionInfo":{"status":"aborted","timestamp":1648128879194,"user_tz":-60,"elapsed":309,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["from sklearn.linear_model import Lasso\n","lasso_reg=Lasso(alpha=0.1, fit_intercept= True, normalize = True, max_iter=1e5)"]},{"cell_type":"markdown","metadata":{"id":"z5iEbZ9zFHk3"},"source":["What is the role of the option `fit_intercept`?\n","*The idea is too ask lasso to add the beta0 (the intercept) to its penality term*."]},{"cell_type":"markdown","metadata":{"id":"3IdYpQqWFHk4"},"source":["### 2. Fit Ridge regression"]},{"cell_type":"markdown","metadata":{"id":"iY2NJlAdFHk6"},"source":["* Fit the ridge regression on the training data previously created."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_uLIegHWFHk7","executionInfo":{"status":"aborted","timestamp":1648128879194,"user_tz":-60,"elapsed":308,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["ridge_reg.fit(x_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"G38c1spzFHk9"},"source":["* Compute the root mean square error of the fitted model on both the training and test set. What do you observe?\n","Plus grand erreur de prédiction sur le testing data set que le training. Mais pas égal à 0 pour le training, car ridge empêche overfitting."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FpMOr00PFHk-","executionInfo":{"status":"aborted","timestamp":1648128879195,"user_tz":-60,"elapsed":309,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","mse_train_ridge=mean_squared_error(y_train, ridge_reg.predict(x_train), squared=False)\n","mse_train_ridge"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JRdnF_EvFHlA","executionInfo":{"status":"aborted","timestamp":1648128879195,"user_tz":-60,"elapsed":308,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["mse_test_ridge=mean_squared_error(y_test, ridge_reg.predict(x_test), squared=False)\n","mse_test_ridge"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YQ10cadhFHlC","executionInfo":{"status":"aborted","timestamp":1648128879196,"user_tz":-60,"elapsed":309,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["# R^2: 1 - E[(Y - Y_hat)^2]/E[(Y - E[Y])^2] \n","# (proportion of variability of Y explained by fitted model)\n","1 - mean_squared_error(y_test, ridge_reg.predict(x_test)) / np.var(y_test)"]},{"cell_type":"markdown","metadata":{"id":"9VHLupPcFHlE"},"source":["### 4. Plot Ridge regression coefficients"]},{"cell_type":"markdown","metadata":{"id":"KuKqV978FHlF"},"source":["We now want to plot the coefficients of the ridge regression for different values of the penalty parameter."]},{"cell_type":"markdown","metadata":{"id":"UMmE8cF1FHlF"},"source":["* Create a grid, named `grid`, of penalty values ranging from `1e-4` to `1e4`."]},{"cell_type":"code","source":["ls"],"metadata":{"id":"l_Yf7PkKLdCZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n7YyWtojFHlG","executionInfo":{"status":"aborted","timestamp":1648128879197,"user_tz":-60,"elapsed":310,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV, KFold\n","# grid = np.arange(1e-4, 1e4, 100)\n","grid=np.array([1e-4*10**k for k in range(9)]) #why like this ?\n"]},{"cell_type":"markdown","metadata":{"id":"3KeScOCOFHlH"},"source":["* Fill in the `??` below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60mmPI5MFHlI","executionInfo":{"status":"aborted","timestamp":1648128879197,"user_tz":-60,"elapsed":309,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["coefs_ridge = []\n","for alph in grid:\n","    ridge_reg.set_params(alpha= alph)\n","    ridge_reg.fit(x_train, y_train) #train ou test? train ! Choisir l'hyperparameter fait partie du training.\n","    coefs_ridge.append(ridge_reg.coef_[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"41ZXcbUhFHlI","executionInfo":{"status":"aborted","timestamp":1648128879198,"user_tz":-60,"elapsed":310,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["plt.figure(figsize=(17,9))\n","plt.plot(np.log10(grid), coefs_ridge)\n","plt.legend(X.columns)"]},{"cell_type":"markdown","metadata":{"id":"RCbcqb5GFHlJ"},"source":["### 5. Fit Lasso regression"]},{"cell_type":"markdown","metadata":{"id":"kFWjNXf_FHlM"},"source":["* Fit the lasso regression on the training data previously created."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-03-11T17:40:09.034119Z","start_time":"2021-03-11T17:40:07.202128Z"},"id":"qKV_vBtOFHlN","executionInfo":{"status":"aborted","timestamp":1648128879199,"user_tz":-60,"elapsed":311,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["lasso_reg.fit(x_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"DVGIi8b_FHlP"},"source":["* Compute the root mean square error of the fitted model on both the training and test set. What do you observe?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DewXpcxeFHlQ","executionInfo":{"status":"aborted","timestamp":1648128879201,"user_tz":-60,"elapsed":54,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["mse_train_lasso=mean_squared_error(y_train, lasso_reg.predict(x_train), squared=False)\n","mse_train_lasso"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I_J0PZo7FHlQ","executionInfo":{"status":"aborted","timestamp":1648128879202,"user_tz":-60,"elapsed":53,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["mse_train_lasso/mse_train_ridge*100"]},{"cell_type":"markdown","metadata":{"id":"3PCG2rQ6FHlR"},"source":["*mse on train with lasso is $96\\%$ of the ridge mse. So they are fairly similar*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kZBNTqFEFHlT","executionInfo":{"status":"aborted","timestamp":1648128879203,"user_tz":-60,"elapsed":50,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["mse_test_lasso=mean_squared_error(y_test, lasso_reg.predict(x_test), squared=False)\n","mse_test_lasso"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mS06przoFHlU","executionInfo":{"status":"aborted","timestamp":1648128879204,"user_tz":-60,"elapsed":50,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["mse_test_lasso/mse_test_ridge*100"]},{"cell_type":"markdown","metadata":{"id":"gMJXbNSlFHlV"},"source":["*mse on test with lasso is $104\\%$ of the ridge mse. So they are fairly similar*"]},{"cell_type":"markdown","metadata":{"id":"sgcfUJfhFHlX"},"source":["### 6. Plot Lasso coefficients"]},{"cell_type":"markdown","metadata":{"id":"OykwmsROFHlY"},"source":["As above, we want to plot the coefficients of the lasso regression for different values of the penalty parameter."]},{"cell_type":"markdown","metadata":{"id":"F-pHJ1nQFHlY"},"source":["* Fill in the `??` below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2vGrIYOtFHlZ","executionInfo":{"status":"aborted","timestamp":1648128879207,"user_tz":-60,"elapsed":51,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["coefs_lasso = []\n","for alph in grid:\n","    lasso_reg.set_params(alpha=alph)\n","    lasso_reg.fit(x_train, y_train) #train or test?\n","    coefs_lasso.append(lasso_reg.coef_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rSO7yhA9FHlZ","executionInfo":{"status":"aborted","timestamp":1648128879208,"user_tz":-60,"elapsed":50,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["plt.figure(figsize=(17,9))\n","plt.plot(np.log10(grid), coefs_lasso)\n","plt.legend(X.columns)"]},{"cell_type":"markdown","metadata":{"id":"HRjNwXjFFHla"},"source":["### 7. Prepare CV"]},{"cell_type":"markdown","metadata":{"id":"qbeMrm3qFHlc"},"source":["At this point, we want to find the optimal penalty parameter for our models.\n","We will use 10-fold cross-validation."]},{"cell_type":"markdown","metadata":{"id":"8vWCr4yyFHld"},"source":["* Using the `KFold` class from `sklearn.model_selection` and instatiate an object named `folds`. Set the number of splits equal to 10, the random seed equal to 42, and make sure to shuffle the rows."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7tx73mFwFHle","executionInfo":{"status":"aborted","timestamp":1648128879209,"user_tz":-60,"elapsed":50,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["from sklearn.model_selection import KFold\n","folds=KFold(n_splits=10, shuffle=True, random_state=42)\n"]},{"cell_type":"markdown","metadata":{"id":"dhO7rxMmFHlg"},"source":["### 8. CV for Ridge"]},{"cell_type":"markdown","metadata":{"id":"ds_4zLYDFHlg"},"source":["* Define a grid of penalty parameters for the ridge regression. You can use the same values used for the grid above. Name the object `ridge_grid`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"od5Tnm2-FHlh","executionInfo":{"status":"aborted","timestamp":1648128879209,"user_tz":-60,"elapsed":49,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["ridge_grid=grid"]},{"cell_type":"markdown","metadata":{"id":"Cs33IlRQFHlk"},"source":["* Create a dictionary with the key-value pair `\"alpha\"`, `ridge_grid`. What is the use of this object?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5T6MIkkaFHlk","executionInfo":{"status":"aborted","timestamp":1648128879210,"user_tz":-60,"elapsed":50,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["hyper_parameters={\"alpha\" : ridge_grid}"]},{"cell_type":"markdown","metadata":{"id":"KFIivjcrFHll"},"source":["*It will be used to test different alpha values of the ridge fit.*"]},{"cell_type":"markdown","metadata":{"id":"-dHX2S4LFHll"},"source":["* Import the class `GridSearchCV` from `sklearn.model_selection` and use it to instantiate a **cross-validation object** for the ridge regression. Make sure to include the following parameters: `estimator`, `param_grid`, `scoring`, `cv`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hkBW5LOvFHll","executionInfo":{"status":"aborted","timestamp":1648128879211,"user_tz":-60,"elapsed":49,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","ridge_cv = GridSearchCV(estimator=ridge_reg, param_grid=hyper_parameters, scoring=\"neg_mean_squared_error\",\n","                       cv=folds)"]},{"cell_type":"markdown","metadata":{"id":"E7qfFZfoFHln"},"source":["* Run the cross-validation by calling the `fit` method of the **cross-validation object** that you created at the point before."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k1WFzO__FHln","executionInfo":{"status":"aborted","timestamp":1648128879211,"user_tz":-60,"elapsed":48,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["ridge_cv.fit(x_train,y_train)"]},{"cell_type":"markdown","metadata":{"id":"Rs-hqUL0FHlo"},"source":["* We want to plot the cross-validation error against different values of the penalty parameter. Fill in the `??`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7eUsB_YFHlp","executionInfo":{"status":"aborted","timestamp":1648128879212,"user_tz":-60,"elapsed":48,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["mean_scores = -ridge_cv.cv_results_[\"mean_test_score\"]\n","std_scores = ridge_cv.cv_results_[\"std_test_score\"] /np.sqrt(10)\n","alphas = np.array([k for k in ridge_cv.cv_results_[\"param_alpha\"].data]) \n","\n","best_index = np.argmin(mean_scores) # index of the alpha with the lowest MSE estimate\n","min_alpha_ridge = ridge_grid[best_index]\n","print(\"Minimum alpha:\", min_alpha_ridge)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lq4HT2o-FHlq","executionInfo":{"status":"aborted","timestamp":1648128879214,"user_tz":-60,"elapsed":50,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["ridge_cv.cv_results_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ReOeb8YxFHlr","executionInfo":{"status":"aborted","timestamp":1648128879214,"user_tz":-60,"elapsed":49,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["plt.errorbar(x = np.log10(alphas), y = mean_scores, yerr = std_scores, fmt='o', capsize=3)\n","\n","plt.axvline(np.log10(min_alpha_ridge), ls='dotted', color=\"grey\")#vertical line at the k yielding minimum CV MSE\n","\n","plt.title(\"Ridge regressor CV error\")\n","plt.xlabel('log(lambda)')\n","plt.ylabel('Mean Squared Error')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"PEgGCf0SFHls"},"source":["### 9. CV for Lasso"]},{"cell_type":"markdown","metadata":{"id":"F-S7PeM-FHlu"},"source":["* Define a grid of penalty parameters for the lasso regression. You can use the same values used for the grid above. Name the object `lasso_grid`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hM8dQ5BzFHlv","executionInfo":{"status":"aborted","timestamp":1648128879215,"user_tz":-60,"elapsed":49,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["lasso_grid=ridge_grid"]},{"cell_type":"markdown","metadata":{"id":"g8NiyFXhFHlw"},"source":["* Create a dictionary with the key-value pair `\"alpha\"`, `lasso_grid`. What is the use of this object?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Umj7-JG-FHlw","executionInfo":{"status":"aborted","timestamp":1648128879215,"user_tz":-60,"elapsed":48,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["hyper_parameters_lasso = {\"alpha\": lasso_grid}"]},{"cell_type":"markdown","metadata":{"id":"vwC0fXTWFHlx"},"source":["* Import the class `GridSearchCV` from `sklearn.model_selection` and use it to create a **cross-validation object** for the lasso regression. Make sure to include the following parameters: `estimator`, `param_grid`, `scoring`, `cv`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l1SHb7rQFHly","executionInfo":{"status":"aborted","timestamp":1648128879216,"user_tz":-60,"elapsed":48,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","lasso_cv=GridSearchCV(estimator=lasso_reg, param_grid=hyper_parameters_lasso, scoring = \"neg_mean_squared_error\", cv = folds)\n"]},{"cell_type":"markdown","metadata":{"id":"0_vJpG21FHlz"},"source":["* Run the cross-validation by calling the `fit` method of the **cross-validation object** that you created at the point before."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SCEn5PAGFHl1","executionInfo":{"status":"aborted","timestamp":1648128879217,"user_tz":-60,"elapsed":48,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["lasso_cv.fit(x_train,y_train)"]},{"cell_type":"markdown","metadata":{"id":"5DRVz2ScFHl2"},"source":["* We want to plot the cross-validation error against different values of the penalty parameter. Fill in the `??`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tMW7cjiBFHl4","executionInfo":{"status":"aborted","timestamp":1648128879219,"user_tz":-60,"elapsed":49,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["# Choose best model according to 1-se rule\n","mean_scores = -lasso_cv.cv_results_[\"mean_test_score\"]\n","std_scores = lasso_cv.cv_results_[\"std_test_score\"] /np.sqrt(10)\n","alphas = lasso_cv.cv_results_[\"param_alpha\"].data\n","alphas = pd.to_numeric(alphas)\n","\n","best_index = np.argmin(mean_scores)\n","min_alpha_lasso = alphas[best_index]\n","print(\"Minimum alpha:\", min_alpha_lasso)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h-89hdLVFHl9","executionInfo":{"status":"aborted","timestamp":1648128879220,"user_tz":-60,"elapsed":50,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["plt.errorbar(x=np.log10(alphas),  y=-ridge_cv.cv_results_[\"mean_test_score\"], yerr = ridge_cv.cv_results_[\"std_test_score\"], fmt='o', capsize=3)\n","\n","plt.axvline(np.log10(min_alpha_lasso), ls='dotted', color=\"grey\")#vertical line at the k yielding minimum CV MSE\n","\n","plt.title(\"Lasso regressor CV error\")\n","plt.xlabel('log(lambda)')\n","plt.ylabel('Mean Squared Error')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"tn8N1DAoFHl-"},"source":["### 10. Compute performance of the two best models"]},{"cell_type":"markdown","metadata":{"id":"fFox5GC1FHmL"},"source":["* Given the optimal tuning parameter of the ridge and lasso regression, refit both models on the entire training data set. Furthermore, compute their root mean square error on the test set. How do they compare to the errors obtained before performing the cross-validation?\n","\n","_Hint_: As optimal tuning parameter, choose the one that minimizes the Mean Squared Error and not the one according to the 1-standard error rule."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KtVXHl7sFHmM","executionInfo":{"status":"aborted","timestamp":1648128879221,"user_tz":-60,"elapsed":50,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["# Refit ridge on training and evaluate on test\n","best_ridge_reg=Ridge(alpha=min_alpha_ridge, fit_intercept= True, normalize = True, max_iter=1e5)\n","best_ridge_reg.fit(x_train,y_train)\n","\n","final_mse_test_ridge=mean_squared_error(y_test, best_ridge_reg.predict(x_test), squared=False)\n","print(\"the score of the ridge regression with the best hyperparameter is:\", final_mse_test_ridge, \"while when not choosing the best hyperparameter, its score was\",mse_test_ridge)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qjq_-hvDFHmO","executionInfo":{"status":"aborted","timestamp":1648128879222,"user_tz":-60,"elapsed":51,"user":{"displayName":"Victor Victorson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15876608535815643552"}}},"outputs":[],"source":["# Refit lasso on training and evaluate on test\n","best_lasso_reg=Lasso(alpha=min_alpha_lasso, fit_intercept= True, normalize = True, max_iter=1e5)\n","best_lasso_reg.fit(x_train,y_train)\n","\n","final_mse_test_lasso=mean_squared_error(y_test, best_lasso_reg.predict(x_test), squared=False)\n","print(\"the score of the lasso regression with the best hyperparameter is:\", final_mse_test_lasso, \"while when not choosing the best hyperparameter, its score was\",mse_test_lasso)"]},{"cell_type":"markdown","metadata":{"id":"qfiCdD59FHmP"},"source":["## Problem 2"]},{"cell_type":"markdown","metadata":{"id":"2QbPDe65FHmQ"},"source":["In this problem, you are asked to derive the closed-form solution for the ridge regression coefficients.\n","\n","Let $\\mathbf{X}\\in\\mathbb{R}^{n\\times p}$ denote the matrix of predictors, and let $\\mathbf{y}\\in\\mathbb{R}^n$ denote the target vector.\n","\n","The optimal ridge regression coefficient vector $\\beta^*$, with parameter $\\lambda > 0$, is defined as\n","\n","$$\\beta^* := \\arg\\min_{\\beta\\in\\mathbb{R}^p} \\ (\\mathbf{y} - \\mathbf{X}\\beta)^T(\\mathbf{y} - \\mathbf{X}\\beta) + \\lambda \\beta ^T\\beta.$$\n","\n","Show that \n","\n","\n","$$\\beta^*  = (\\mathbf{X}^T\\mathbf{X} + \\lambda \\mathbf{I}_p)^{-1} \\mathbf{X}^T \\mathbf{y},$$\n","\n","where $\\mathbf{I}_p$ denote the identity matrix of size $p\\times p$."]},{"cell_type":"markdown","metadata":{"id":"5kGmjkZ_FHmQ"},"source":["$\\newcommand{\\mby}{\\mathbf{y}}$\n","We want to find the $β^*$ such that $(\\mathbf{y} - \\mathbf{X}\\beta)^T(\\mathbf{y} - \\mathbf{X}\\beta) + \\lambda \\beta ^T\\beta.$ is minimized. For this, we first compute $\\frac{\\partial}{\\partial β}\\left((\\mathbf{y} - \\mathbf{X}\\beta)^T(\\mathbf{y} - \\mathbf{X}\\beta) + \\lambda \\beta ^T\\beta\\right)$:\n","\n","$\\begin{align*}\n","\\frac{\\partial}{\\partial β}\\left((\\mathbf{y} - \\mathbf{X}\\beta)^T(\\mathbf{y} - \\mathbf{X}\\beta) + \\lambda \\beta ^T\\beta\\right) &= \\frac{\\partial}{\\partial β}\\left(\\mathbf{y}^T\\mathbf{y}-\\mathbf{y}^T\\mathbf{X}β-β^T\\mathbf{X}^T\\mathbf{y}+β^T\\mathbf{X}^T\\mathbf{X}β+λβ^Tβ\\right)\\\\\n","&=-\\mathbf{y}^T\\mathbf{X}-\\underbrace{\\mathbf{y}^T\\mathbf{X}}_{\\frac{\\partial}{\\partial β}(β^tA)=A^T}+\\underbrace{2\\mathbf{X}^T\\mathbf{X}β}_{\\frac{\\partial}{\\partial β}((Aβ)^TAβ)=2Aβ} +2λβ\\\\\n","&=-2\\mathbf{y}^T\\mathbf{X}+2\\mathbf{X}^T\\mathbf{X}β +2λ\n","\\end{align*}$\n","Now we equate it to $0$:\n","$\\begin{align*}\n","-2\\mathbf{y}^T\\mathbf{X}+2\\mathbf{X}^T\\mathbf{X}β +2λβ&=0\\\\\n","\\Leftrightarrow-\\mathbf{y}^T\\mathbf{X}+\\mathbf{X}^T\\mathbf{X}β +λβ&=0\\\\\n","\\Leftrightarrow \\left(\\mathbf{X}^T\\mathbf{X}+λId_{p}\\right)β=\\mathbf{y}^T\\mathbf{X}\\\\\n","\\Leftrightarrow β=\\left(\\mathbf{X}^T\\mathbf{X}+λId_{p}\\right)^{-1}\\mathbf{y}^T\\mathbf{X}\n","\\end{align*}$\n","\n","We then check that $\\frac{\\partial}{\\partial β^T}\\left(-2\\mathbf{y}^T\\mathbf{X}+2\\mathbf{X}^T\\mathbf{X}β +2λβ\\right)$ is positive definite:\n","$$\\frac{\\partial}{\\partial β^T}\\left(-2\\mathbf{y}^T\\mathbf{X}+2\\mathbf{X}^T\\mathbf{X}β +2λβ\\right)=2\\mathbf{X}\\mathbf{X}^T +2λId_{p}$$\n","\n","And so\n","$$\\mathbf{v}^T\\left(2\\mathbf{X}\\mathbf{X}^T +2λId_{p}\\right)\\mathbf{v}=2\\underbrace{\\mathbf{v}^T\\mathbf{X}\\mathbf{X}^T\\mathbf{v}}_{=||\\mathbf{X}^Tv||^2>0}+2\\underbrace{λ}_{>0}\\overbrace{v^Tv}^{=||v||^2>0}>0$$"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"216px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"Exercise_04_grp_17_anotated.ipynb","provenance":[],"collapsed_sections":["RCbcqb5GFHlJ","sgcfUJfhFHlX"]}},"nbformat":4,"nbformat_minor":0}