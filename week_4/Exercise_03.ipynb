{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Exercise session 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise session we will focus mainly on model assessment. You will learn how to use and apply some of the error estimation techniques seen in class, using scikit-learn (parts 1 and 2).\n",
    "\n",
    "To illustrate these techniques in context, we will continue where we left out in exercise session 01, with the housing dataset. You can export and use your resulting, cleaned, dataframe from the first session, or you can download it on moodle in this week's section (with the cleaning and feature engineering from the first session already performed).\n",
    "\n",
    "The third part of this notebook will introduce scikit-learn's Pipelines, which are a very useful tool that can be used, among other things, to avoid validation overfitting during cross-validation.\n",
    "\n",
    "Due to this last part making the practical part a bit longer, there will be no \"theoretical\" exercise this week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Introduction and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:07.020276Z",
     "start_time": "2021-03-11T17:40:05.837658Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the clean housing dataset with `pd.read_csv` and take a quick look at it, to verify that it is in the desired shape (display the dataframe, check its \"infos\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:07.132428Z",
     "start_time": "2021-03-11T17:40:07.023280Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:07.182414Z",
     "start_time": "2021-03-11T17:40:07.141866Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the dataframe into the features `X` and the target variable `y`: (remember, we want to predict the median house value, given the other variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:07.198142Z",
     "start_time": "2021-03-11T17:40:07.184411Z"
    }
   },
   "outputs": [],
   "source": [
    "X = ??\n",
    "y = ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fitting KNN and expected error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:09.034119Z",
     "start_time": "2021-03-11T17:40:07.202128Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the following sections will not only be to use a k-Nearest neighbors regression model in order to predict the expected median household values, based on the other features, but also to assess how our model is performing, that is, its expected prediction error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, import the same KNN regression model that you briefly used in the first exercise session, and fit it on the whole dataset for the desired prediction task. Use as a hyper-parameter `k=1` neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:09.192001Z",
     "start_time": "2021-03-11T17:40:09.036197Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, evaluate its root mean squared error using `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:09.208151Z",
     "start_time": "2021-03-11T17:40:09.196240Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:09.390467Z",
     "start_time": "2021-03-11T17:40:09.212215Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe? What does that say probably say about the model? Does that mean that the model is performing well, you think?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, separate the data into `X_train` `y_train` and `X_test` `y_test`, and fit a KNN regressor on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:09.408531Z",
     "start_time": "2021-03-11T17:40:09.393695Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:09.441855Z",
     "start_time": "2021-03-11T17:40:09.411962Z"
    }
   },
   "outputs": [],
   "source": [
    "# fill out the ??\n",
    "X_train, X_test, y_train, y_test = train_test_split(??, ??, test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:09.558366Z",
     "start_time": "2021-03-11T17:40:09.443853Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check its RMSE both on the training and on the test set, do you observe something that you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:09.741617Z",
     "start_time": "2021-03-11T17:40:09.562045Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:09.956833Z",
     "start_time": "2021-03-11T17:40:09.744099Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've learned about the Bias-Variance tradeoff during the last lecture. Does the model suffer from too much bias or too much variance? Does that mean that it is too \"flexible\", or not enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fitting a model, we are interested in its expected generalization error (the expected error on unseen data).\n",
    "In order to estimate this expected error, a more stable way to estimate it than with a train-test split is to use cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a new KNN regressor instance with the same hyper-parameter as before, and estimate its expected generalization error with 10 folds cross-validation on `X` and `y`.\n",
    "\n",
    "Print the average generalization RMSE for each fold as well as the cross-validation error estimate.\n",
    "\n",
    "\n",
    "_Remark:_ during fitting sklearn maximizes \"scores\" instead of minimizing losses, that is why we specify `scoring=\"neg_mean_squared_error\"` below, as we maximize the negative MSE instead of minimizing the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:09.972225Z",
     "start_time": "2021-03-11T17:40:09.959527Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:12.261659Z",
     "start_time": "2021-03-11T17:40:09.978240Z"
    }
   },
   "outputs": [],
   "source": [
    "knn = ??\n",
    "CVscores = cross_val_score(??, ??, ??, scoring=\"neg_mean_squared_error\", cv=??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:12.276853Z",
     "start_time": "2021-03-11T17:40:12.261659Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:12.292393Z",
     "start_time": "2021-03-11T17:40:12.281184Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in `cross_val_score` you can simply specify the number of folds with the argument `cv=10`. By default, sklearn splits the data equally into the specified number of folds without shuffling it first. This behaviour might be useful when, for example, some time dependence between observations needs to be kept for specific models. However, if we assume that the observations are independent, it might be a better idea to shuffle observations (rows) before splitting, to avoid imbalances within folds, created by any kind of prior implicit sorting of the observations.\n",
    "\n",
    "You can control the splitting method and, in particular, shuffle the data prior to splitting in folds, by specifying a [KFold object](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators) instead of a simple number for the `cv` argument.\n",
    "\n",
    "Repeat the cross-validation estimation by, this time, shuffling the data for the folds split. Do you notice any difference with the estimated RMSEs for each fold? If yes, why do you think (speculate) it might be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:12.308229Z",
     "start_time": "2021-03-11T17:40:12.295903Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:14.558951Z",
     "start_time": "2021-03-11T17:40:12.309266Z"
    }
   },
   "outputs": [],
   "source": [
    "knn = ??\n",
    "folds = KFold(n_splits=?? , shuffle=??, random_state=1)\n",
    "CVscores = cross_val_score(??, ??, ??, scoring=??, cv=??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:14.574865Z",
     "start_time": "2021-03-11T17:40:14.560945Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyper-Parameter tuning and Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part, we \"arbitrarily\" chose a hyper-parameter value for our model. However, this value might not be optimal. Usually, we want to compare the model's expected error for a range of different possible hyper-parameters, in order to choose the best one for the task at hand. (Remember the optimal value depends on the specific data we try to model, and there cannot be a \"best\" hyper-parameter value overall, this is often called the *no free lunch theorem*.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sklearn, [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) performs a grid-search over the given range of hyper-parameter values, by estimating the cross-validation error for each value in the given grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:14.590383Z",
     "start_time": "2021-03-11T17:40:14.576833Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, instanciate a new kNN regressor (no need to specify a k value), and specify the grid of hyper-parameter values in a dictionary of the form `{\"hyper_param_name\" : values_to_try}`.\n",
    "\n",
    "Choose equally spaced values between $1$ and $49$, with an increment of $2$ as a grid of values to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:40:14.606147Z",
     "start_time": "2021-03-11T17:40:14.600065Z"
    }
   },
   "outputs": [],
   "source": [
    "knn = ??\n",
    "\n",
    "hyper_parameters = {\"??\" : ??}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the Grid-search with 10-fold cross-validation, to estimate the model's generalization error for the chosen grid of k values. Don't forget to shuffle the data for the fold split.\n",
    "\n",
    "_Hint:_ `GridSearchCV` is an object, you need to instanciate it and fit it (like a ML model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:41:50.397197Z",
     "start_time": "2021-03-11T17:40:14.612978Z"
    }
   },
   "outputs": [],
   "source": [
    "knnCV = GridSearchCV(estimator=??, param_grid=??, scoring=??,\n",
    "                       cv=KFold(??=??, ??=??, random_state=1))\n",
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted grid-search object has an attribute `cv_results_` containing the grid search results as a dictionary. Inspect its contents and try to understand what each variable means. (It might be easier to visualize if you convert the dictionary into a DataFrame.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:41:50.501157Z",
     "start_time": "2021-03-11T17:41:50.400219Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the `GridSearchCV` results that you inspected, extract the k value yielding the \"best\" (lowest) MSE estimate\n",
    "\n",
    "(Again fill out the `??` below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:41:50.516404Z",
     "start_time": "2021-03-11T17:41:50.505732Z"
    }
   },
   "outputs": [],
   "source": [
    "resCV = knnCV.cv_results_\n",
    "\n",
    "test_MSEs = -resCV[??]\n",
    "std_test_MSEs = resCV[??]\n",
    "k_grid = resCV[??].data\n",
    "\n",
    "index_best = ?? # index of the k value with the lowest MSE estimate\n",
    "best_k = ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now extract the more parsimonious k value obtained by the \"one standard error rule\" seen in class.\n",
    "\n",
    "_Hint_: You might first need to answer this question: *Are larger or smaller k values yielding a more parsimonious model (low \"flexibility\" and variance)?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:41:50.531648Z",
     "start_time": "2021-03-11T17:41:50.520108Z"
    }
   },
   "outputs": [],
   "source": [
    "one_std_rule_best_k = ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better visualize how the expected error varies as a function of the hyper-parameter k, we can construct a MSE plot with standard deviations from the `GridSearchCV`. It is also nice to highlight the two important k values discussed just above (with vertical lines for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:41:50.943235Z",
     "start_time": "2021-03-11T17:41:50.534583Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,6))\n",
    "plt.errorbar(x=??, y=??, yerr=??, fmt='o', capsize=3)\n",
    "\n",
    "plt.axvline(??, ls='dotted', color=\"grey\")#vertical line at the k yielding minimum CV MSE\n",
    "plt.axvline(??, ls='dotted', color=\"grey\")#vertical line at best k value according to 1 std err rule\n",
    "\n",
    "plt.title(\"kNN regressor CV error\")\n",
    "plt.xlabel('k (nb neighbors)')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, how does the expected generalization error of the model with the newly selected k value compare to our initial k choice, prior to cross-validation based selection?\n",
    "\n",
    "And for the other k values, how to you think the training error compares to the CV error. You can compare them by adding the training error as a function of the hyper-parameter value to the plot above. (*Hint: [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) can return the training scores, but it is more expensive computationally. You can also compute them yourself easily on X and y by iterating over the k_grid.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now fit the model, with the newly selected k value to the whole dataset. This will be the final kNN model, chosen based on empirical evidence :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:41:51.116382Z",
     "start_time": "2021-03-11T17:41:50.949202Z"
    }
   },
   "outputs": [],
   "source": [
    "knn_final = ??\n",
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Remark:_ KNN was used as an example in this session, but we could also do the same with any other machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pipelines and cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This third part is not mandatory for the hand-in***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one essential detail that has been left-out in the first two parts of this notebook.\n",
    "As kNN relies on euclidean distance to select the nearest points, it is always better to work with standardized data (each variable rescaled to be centered at 0 and have unit variance). That way the same distance along each feature axis is proportional for each variable.\n",
    "\n",
    "As you've seen in the first week's tutorial, you can use [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to rescale the variables.\n",
    "\n",
    "When you leave some validation/test data out to evaluate your model, it is best practice to **not use it for any type of estimation**, to avoid having a biased error estimate (as, otherwise, you already \"took\" some information from the validation data). This also holds for estimating the mean and standard deviation of variables, with the `StandardScaler`.\n",
    "\n",
    "Here is an example of how to scale the data properly, in case of a train-test split, without overfitting the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:41:51.154661Z",
     "start_time": "2021-03-11T17:41:51.117379Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Create the scaler:\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Estimate the mean and variances for each variable on the training set only:\n",
    "scaler.fit(X_train)\n",
    "\n",
    "print(\"Original means:\", scaler.mean_)\n",
    "print(\"Original Variances:\", scaler.var_)\n",
    "\n",
    "#Scale the training and test features, using the previously estimated means and variances\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could then fit our kNN model on the scaled training set and evaluate it on the test set, without having \"cheated\", by using information from the test set in our estimations.\n",
    "\n",
    "If you now think about estimating the error using cross-validation, you'll quickly realize that not overfitting with the scaler gets a bit more complicated, as we need to perform the above procedure separately for each fold, before fitting the model. That is when Pipelines come into play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Cross-validation with Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) you can define sequentially, all the steps of your transformation + fitting process. For example standard scaling + kNN. The syntax is the following (complete the ??): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Hint_: each step in the pipeline is defines as a tuple: `(\"desired_step_name\", Transformer_or_predictor_object)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:41:51.170375Z",
     "start_time": "2021-03-11T17:41:51.154661Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:41:51.186193Z",
     "start_time": "2021-03-11T17:41:51.174604Z"
    }
   },
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline([(\"scaler\", ??),\n",
    "                     (\"kNN\", ??)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then fit the entire Pipeline on the training set, and predict on the test set, as if it was a single model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:41:51.983856Z",
     "start_time": "2021-03-11T17:41:51.189631Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat the grid-search (section 2, except the training error question) by using the new Pipeline instead of the simple kNN as a model.\n",
    "\n",
    "_Hint 1:_ There shouldn't be too many changes in the code.\n",
    "\n",
    "_Hint 2:_ You'll need to add the pipeline step name before the parameter name for the grid in `GridSearchCV`. (i.e. replace `\"n_estimators\"` by `\"kNN__n_estimators\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:41:51.999638Z",
     "start_time": "2021-03-11T17:41:51.986389Z"
    }
   },
   "outputs": [],
   "source": [
    "#Declare Pipe and grid:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:44:16.754487Z",
     "start_time": "2021-03-11T17:41:52.001769Z"
    }
   },
   "outputs": [],
   "source": [
    "#Declare and fit the grid search:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:44:16.769914Z",
     "start_time": "2021-03-11T17:44:16.756406Z"
    }
   },
   "outputs": [],
   "source": [
    "#Compute \"best\" k value and its index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:44:16.786264Z",
     "start_time": "2021-03-11T17:44:16.773155Z"
    }
   },
   "outputs": [],
   "source": [
    "#compute best k based on one std error rule:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:44:17.180534Z",
     "start_time": "2021-03-11T17:44:16.789396Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plot the grid-search results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:44:17.352097Z",
     "start_time": "2021-03-11T17:44:17.183787Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fit the final model:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "216px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
